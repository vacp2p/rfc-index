#!/usr/bin/env python3
"""
Validate RFC metadata tables and auto-assign missing slugs.

By default, this script writes fixes for missing/blank `Slug` values and
returns non-zero on any validation issue.
Use `--check` to run in read-only mode.
"""
from __future__ import annotations

import argparse
import re
from dataclasses import dataclass
from pathlib import Path
from typing import Dict, List, Optional, Tuple

ROOT = Path(__file__).resolve().parent.parent
DOCS = ROOT / "docs"

EXCLUDE_FILES = {"README.md", "SUMMARY.md", "about.md", "template.md"}
REQUIRED_FIELDS = ("name", "slug", "status", "category", "editor")
ALLOWED_STATUS = {"raw", "draft", "stable", "deprecated", "deleted"}
ALLOWED_CATEGORIES = {
    "standards track",
    "informational",
    "best current practice",
    "process",
    "infrastructure",
    "networking",
}

SEPARATOR_RE = re.compile(r"^\|\s*:?-{3,}:?\s*\|\s*:?-{3,}:?\s*\|$")
ROW_RE = re.compile(r"^\|\s*([^|]+?)\s*\|\s*(.*?)\s*\|$")
HEADER_RE = re.compile(r"^\|\s*field\s*\|\s*value\s*\|$", re.IGNORECASE)
NUMERIC_RE = re.compile(r"^[1-9][0-9]*$")


@dataclass
class TableInfo:
    start: int
    separator: int
    end: int
    rows: Dict[str, Tuple[int, str, str]]


@dataclass
class DocInfo:
    path: Path
    rel: Path
    lines: List[str]
    table: Optional[TableInfo]
    errors: List[str]
    assigned_slug: Optional[int] = None

    def meta(self) -> Dict[str, str]:
        if not self.table:
            return {}
        return {k: v for k, (_, _, v) in self.table.rows.items()}


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(description="Validate RFC metadata.")
    parser.add_argument(
        "--check",
        action="store_true",
        help="Read-only mode; do not write missing slugs.",
    )
    return parser.parse_args()


def discover_docs() -> List[Path]:
    files = []
    for path in DOCS.rglob("*.md"):
        if path.name in EXCLUDE_FILES:
            continue
        files.append(path)
    return sorted(files)


def find_metadata_table(lines: List[str]) -> Optional[TableInfo]:
    max_scan = min(len(lines), 140)
    for idx in range(max_scan - 1):
        if not HEADER_RE.match(lines[idx].strip()):
            continue
        if not SEPARATOR_RE.match(lines[idx + 1].strip()):
            continue

        rows: Dict[str, Tuple[int, str, str]] = {}
        row_idx = idx + 2
        while row_idx < len(lines) and lines[row_idx].strip().startswith("|"):
            raw = lines[row_idx].strip()
            match = ROW_RE.match(raw)
            if match:
                key_display = match.group(1).strip()
                key = key_display.lower()
                value = match.group(2).strip()
                if key not in rows:
                    rows[key] = (row_idx, key_display, value)
            row_idx += 1

        return TableInfo(start=idx, separator=idx + 1, end=row_idx, rows=rows)
    return None


def read_doc(path: Path) -> DocInfo:
    lines = path.read_text(encoding="utf-8", errors="ignore").splitlines()
    table = find_metadata_table(lines)
    return DocInfo(
        path=path,
        rel=path.relative_to(ROOT),
        lines=lines,
        table=table,
        errors=[],
    )


def next_free_slug(used: set[int]) -> int:
    candidate = max(used, default=0) + 1
    while candidate in used:
        candidate += 1
    return candidate


def assign_missing_slug(doc: DocInfo, slug: int) -> None:
    assert doc.table is not None
    slug_row = doc.table.rows.get("slug")
    if slug_row:
        row_idx, key_display, _ = slug_row
        doc.lines[row_idx] = f"| {key_display} | {slug} |"
    else:
        name_row = doc.table.rows.get("name")
        status_row = doc.table.rows.get("status")
        if name_row:
            insert_idx = name_row[0] + 1
        elif status_row:
            insert_idx = status_row[0]
        else:
            insert_idx = doc.table.separator + 1
        doc.lines.insert(insert_idx, f"| Slug | {slug} |")
    doc.table = find_metadata_table(doc.lines)
    doc.assigned_slug = slug


def collect_used_numeric_slugs(docs: List[DocInfo]) -> set[int]:
    used: set[int] = set()
    for doc in docs:
        if not doc.table:
            continue
        slug = doc.meta().get("slug", "")
        if NUMERIC_RE.fullmatch(slug):
            used.add(int(slug))
    return used


def maybe_assign_slugs(docs: List[DocInfo], check_mode: bool) -> List[DocInfo]:
    if check_mode:
        return []

    changed: List[DocInfo] = []
    used = collect_used_numeric_slugs(docs)
    for doc in docs:
        if not doc.table:
            continue
        slug = doc.meta().get("slug", "").strip()
        if slug:
            continue
        free_slug = next_free_slug(used)
        assign_missing_slug(doc, free_slug)
        used.add(free_slug)
        changed.append(doc)
    return changed


def validate_doc(doc: DocInfo) -> None:
    if not doc.table:
        doc.errors.append("missing metadata table '| Field | Value |'")
        return

    # Ensure standard header rows remain canonical.
    if doc.lines[doc.table.start].strip() != "| Field | Value |":
        doc.errors.append("metadata header row must be exactly '| Field | Value |'")
    if not SEPARATOR_RE.match(doc.lines[doc.table.separator].strip()):
        doc.errors.append("metadata separator row is malformed")

    # Row formatting validation.
    for idx in range(doc.table.start + 2, doc.table.end):
        line = doc.lines[idx].strip()
        if line and not ROW_RE.match(line):
            doc.errors.append(f"malformed metadata row at line {idx + 1}: {line}")

    meta = doc.meta()

    for field in REQUIRED_FIELDS:
        if not meta.get(field, "").strip():
            doc.errors.append(f"missing required metadata field '{field}'")

    status = meta.get("status", "").strip().lower()
    if status and status not in ALLOWED_STATUS:
        allowed = ", ".join(sorted(ALLOWED_STATUS))
        doc.errors.append(f"invalid status '{status}' (allowed: {allowed})")

    rel_parts = set(doc.rel.parts)
    if "deprecated" in rel_parts and status not in {"deprecated", "deleted"}:
        doc.errors.append(
            "file is under '/deprecated/' but status is not deprecated/deleted"
        )

    slug = meta.get("slug", "").strip()
    if slug and not NUMERIC_RE.fullmatch(slug):
        doc.errors.append("slug must be a positive integer")

    category = meta.get("category", "").strip().lower()
    if category and category not in ALLOWED_CATEGORIES:
        allowed = ", ".join(sorted(ALLOWED_CATEGORIES))
        doc.errors.append(
            f"unknown category '{meta.get('category', '')}' (expected one of: {allowed})"
        )


def validate_slug_uniqueness(docs: List[DocInfo]) -> List[str]:
    # Allow duplicated slugs in archived previous-version snapshots.
    slug_map: Dict[int, List[Path]] = {}
    for doc in docs:
        if not doc.table:
            continue
        if "previous-versions" in doc.rel.parts:
            continue
        slug = doc.meta().get("slug", "").strip()
        if not NUMERIC_RE.fullmatch(slug):
            continue
        slug_map.setdefault(int(slug), []).append(doc.rel)

    errors: List[str] = []
    for slug, paths in sorted(slug_map.items()):
        if len(paths) <= 1:
            continue
        joined = ", ".join(str(p) for p in paths)
        errors.append(f"duplicate slug {slug}: {joined}")
    return errors


def write_if_changed(doc: DocInfo) -> None:
    text = "\n".join(doc.lines).rstrip() + "\n"
    doc.path.write_text(text, encoding="utf-8")


def main() -> int:
    args = parse_args()
    docs = [read_doc(path) for path in discover_docs()]

    changed = maybe_assign_slugs(docs, check_mode=args.check)
    for doc in docs:
        validate_doc(doc)

    global_errors = validate_slug_uniqueness(docs)

    if changed:
        for doc in changed:
            write_if_changed(doc)
            print(f"[FIX] Assigned slug {doc.assigned_slug} in {doc.rel}")

    error_count = len(global_errors)
    for doc in docs:
        for error in doc.errors:
            error_count += 1
            print(f"[ERROR] {doc.rel}: {error}")

    for error in global_errors:
        print(f"[ERROR] {error}")

    if error_count:
        print(f"[FAIL] metadata validation failed with {error_count} error(s)")
        return 1

    print(
        "[OK] metadata validation passed"
        + (f"; updated {len(changed)} file(s)" if changed else "")
    )
    return 0


if __name__ == "__main__":
    raise SystemExit(main())
